<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IDP Documentation - implementation_plan</title>
    
<style>
    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        line-height: 1.6;
        color: #333;
        max-width: 900px;
        margin: 0 auto;
        padding: 40px;
        background-color: #f9f9f9;
    }
    .container {
        background-color: white;
        padding: 50px;
        border-radius: 8px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    h1, h2, h3 {
        color: #2c3e50;
        border-bottom: 2px solid #eee;
        padding-bottom: 10px;
        margin-top: 30px;
    }
    h1 { font-size: 2.5em; border-bottom: 3px solid #3498db; }
    h2 { font-size: 1.8em; color: #2980b9; }
    h3 { font-size: 1.3em; color: #16a085; border-bottom: none; }
    
    code {
        font-family: 'Consolas', 'Monaco', monospace;
        background-color: #f0f0f0;
        padding: 2px 5px;
        border-radius: 3px;
        font-size: 0.9em;
    }
    pre {
        background-color: #2d3436;
        color: #dfe6e9;
        padding: 20px;
        border-radius: 5px;
        overflow-x: auto;
        line-height: 1.4;
    }
    pre code {
        background-color: transparent;
        color: inherit;
        padding: 0;
    }
    
    table {
        border-collapse: collapse;
        width: 100%;
        margin: 20px 0;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 12px;
        text-align: left;
    }
    th {
        background-color: #3498db;
        color: white;
    }
    tr:nth-child(even) { background-color: #f2f2f2; }
    
    .checkpoint {
        background-color: #e8f4fd;
        border-left: 5px solid #3498db;
        padding: 15px;
        margin: 20px 0;
    }
    
    .note {
        background-color: #fff9db;
        border-left: 5px solid #fab005;
        padding: 15px;
        margin: 20px 0;
    }

    @media print {
        body { background-color: white; padding: 0; }
        .container { box-shadow: none; border: none; padding: 20px; }
    }
</style>

</head>
<body>
    <div class="container">
        <h1>Plan de Implementación - Proyecto IDP</h1>
<h2>Manuel Cruz Garrote - Universidad del Rosario</h2>
<p><strong>Versión:</strong> Alcance Reducido (Versión Realista)<br />
<strong>Fecha:</strong> Febrero 2026<br />
<strong>Meta:</strong> 7.5/10 - Muy Bueno</p>
<hr />
<h1>Resumen Ejecutivo</h1>
<p>Este plan define la implementación de un sistema de Procesamiento Inteligente de Documentos (IDP) enfocado en el <strong>diferenciador clave</strong>: eliminación de sellos mediante inpainting para mejorar la extracción de texto por OCR.</p>
<p>Dado que trabajo y estudio simultáneamente, he priorizado las funcionalidades <strong>esenciales</strong> que demuestran innovación técnica y tienen aplicabilidad real, descartando features avanzadas que consumirían tiempo sin agregar valor proporcional al objetivo académico.</p>
<hr />
<h1>Problema a Resolver</h1>
<h2>Contexto</h2>
<p>Los sistemas de OCR comerciales (Google Doc AI, AWS Textract, ABBYY) funcionan bien con documentos digitales limpios, pero <strong>fallan significativamente</strong> cuando procesan:</p>
<ol>
<li><strong>Documentos físicos escaneados</strong> con arrugas, manchas, o perspectiva incorrecta</li>
<li><strong>Documentos con sellos oficiales</strong> que obstruyen el texto subyacente</li>
<li><strong>Documentos históricos</strong> con degradación de calidad</li>
</ol>
<h2>Caso de Uso Específico</h2>
<p><strong>Target:</strong> Archivos gubernamentales y notariales en Colombia</p>
<ul>
<li>Millones de documentos físicos pendientes de digitalización</li>
<li>Sellos oficiales obligatorios que cubren información crítica</li>
<li>Necesidad de extraer texto completo para índice de búsqueda</li>
</ul>
<h2>Propuesta de Valor</h2>
<blockquote>
<p><strong>"Recuperar texto que otros sistemas ignoran mediante inpainting inteligente de sellos"</strong></p>
</blockquote>
<p>Ningún competidor comercial ofrece esta funcionalidad de forma integrada.</p>
<hr />
<h1>Arquitectura del Sistema (Versión Reducida)</h1>
<h2>Pipeline Simplificado</h2>
<pre><code>Input: Imagen de documento
    ↓
[1] Preprocesamiento
    - Corrección de rotación
    - Binarización adaptativa
   ↓
[2] Detección de Sellos
    - Método basado en color HSV
    ↓
[3] Inpainting (LaMa)
    - Eliminación inteligente de sellos
    ↓
[4] OCR Multimodal
    - PaddleOCR (primario)
    - Tesseract (fallback)
    ↓
Output: Texto extraído + Métricas
</code></pre>
<h2>Módulos del Sistema</h2>
<h3><code>preprocessing/</code></h3>
<ul>
<li><code>rotation.py</code> - Corrección de rotación con Hough Transform</li>
<li><code>binarization.py</code> - Binarización adaptativa (Otsu)</li>
</ul>
<h3><code>stamps/</code></h3>
<ul>
<li><code>detector.py</code> - Detección por color en espacio HSV</li>
<li><code>inpainting.py</code> - Wrapper para LaMa</li>
</ul>
<h3><code>ocr/</code></h3>
<ul>
<li><code>paddle_engine.py</code> - Motor principal (PaddleOCR)</li>
<li><code>tesseract_engine.py</code> - Fallback</li>
<li><code>ocr_engine.py</code> - Orquestador con estrategia de fallback</li>
</ul>
<h3><code>utils/</code></h3>
<ul>
<li><code>metrics.py</code> - Cálculo de CER, WER, F1</li>
<li><code>visualization.py</code> - Gráficos y comparativas</li>
</ul>
<hr />
<h1>Stack Tecnológico</h1>
<h2>Lenguaje Base</h2>
<ul>
<li><strong>Python 3.10+</strong> (compatibilidad con todas las librerías modernas)</li>
</ul>
<h2>Preprocesamiento</h2>
<ul>
<li><strong>OpenCV 4.8+</strong> - Procesamiento de imágenes</li>
<li>Por qué: Maduro, rápido, bien documentado</li>
<li>Uso: Rotación, binarización, detección de color</li>
</ul>
<h2>OCR</h2>
<ul>
<li><strong>PaddleOCR v2.7</strong> - Motor principal</li>
<li>Por qué: Excelente accuracy en múltiples idiomas</li>
<li>GPU/CPU automático</li>
<li>
<p>Lightweight</p>
</li>
<li>
<p><strong>Tesseract 5.0</strong> - Fallback</p>
</li>
<li>Por qué: Baseline confiable, open-source</li>
</ul>
<h2>Inpainting</h2>
<ul>
<li><strong>LaMa (Large Mask Inpainting)</strong> - Samsung AI 2021</li>
<li>Por qué: Estado del arte en inpainting</li>
<li>Funciona bien con máscaras grandes (sellos)</li>
<li>Modelo pre-entrenado disponible</li>
</ul>
<h2>Infrastructure</h2>
<ul>
<li><strong>PyTorch 2.0+</strong> - Framework para LaMa</li>
<li><strong>NumPy / PIL</strong> - Manipulación de imágenes</li>
<li><strong>Pytest</strong> - Testing</li>
<li><strong>Jupyter</strong> - Experimentación</li>
</ul>
<h2>Datasets</h2>
<ul>
<li><strong>SROIE</strong> (Scanned Receipts OCR and IE) - Benchmark público</li>
<li><strong>Custom Stamp Dataset</strong> - 50 imágenes anotadas manualmente</li>
</ul>
<hr />
<h1>Fases de Implementación</h1>
<h2>FASE 1: MVP Core (CP0 + CP1)</h2>
<p><strong>Objetivo:</strong> Sistema funcional básico de preprocesamiento + OCR</p>
<h3>Entregables:</h3>
<ol>
<li><strong>Dataset preparado</strong></li>
<li>50 sellos anotados</li>
<li>
<p>SROIE descargado y organizado</p>
</li>
<li>
<p><strong>Módulo de Preprocesamiento</strong>
   <code>python
   def preprocess_image(img):
       img = correct_rotation(img)
       img = apply_binarization(img)
       return img</code></p>
</li>
<li>
<p><strong>Motor de OCR Dual</strong>
   <code>python
   def extract_text(img):
       try:
           return paddle_ocr(img)
       except:
           return tesseract_ocr(img)</code></p>
</li>
<li>
<p><strong>Pipeline v1</strong>
   <code>python
   text = extract_text(preprocess_image(input_img))</code></p>
</li>
</ol>
<h3>Criterio de Éxito:</h3>
<ul>
<li>✅ Accuracy &gt;70% en subset SROIE (50 muestras)</li>
<li>✅ Pipeline ejecuta sin errores</li>
<li>✅ Código modularizado y testeado</li>
</ul>
<hr />
<h2>FASE 2: Diferenciador - Inpainting (CP2)</h2>
<p><strong>Objetivo:</strong> Validar que el inpainting mejora significativamente el OCR</p>
<h3>Entregables:</h3>
<ol>
<li>
<p><strong>Detector de Sellos (Simplificado)</strong>
   <code>python
   def detect_stamps_hsv(img):
       hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
       # Define rangos de color típicos de sellos (azul, rojo)
       mask = cv2.inRange(hsv, lower_bound, upper_bound)
       contours = find_contours(mask)
       return filter_valid_stamps(contours)</code></p>
</li>
<li>
<p><strong>Inpainting Integration</strong>
   <code>python
   def remove_stamps(img, stamp_masks):
       model = load_lama_model()
       inpainted = model.inpaint(img, stamp_masks)
       return inpainted</code></p>
</li>
<li>
<p><strong>Pipeline v2</strong>
   <code>python
   stamps = detect_stamps(img)
   img_clean = remove_stamps(img, stamps)
   text = extract_text(preprocess_image(img_clean))</code></p>
</li>
<li>
<p><strong>Experimento de Validación</strong></p>
</li>
<li>30 documentos con sellos</li>
<li>Métrica Before: OCR sin inpainting</li>
<li>Métrica After: OCR con inpainting</li>
<li><strong>Hipótesis:</strong> Mejora &gt;5% en CER/WER</li>
</ol>
<h3>Criterio de Éxito:</h3>
<ul>
<li>✅ Detector identifica &gt;80% de sellos</li>
<li>✅ Inpainting genera resultados visualmente coherentes</li>
<li>✅ <strong>Mejora estadísticamente significativa en OCR (&gt;5%)</strong></li>
</ul>
<hr />
<h2>FASE 3: Validación y Documentación (CP3)</h2>
<p><strong>Objetivo:</strong> Resultados científicos reproducibles + documento académico</p>
<h3>Entregables:</h3>
<ol>
<li><strong>Benchmark en SROIE</strong></li>
<li>Correr pipeline en 100 muestras</li>
<li>Métricas completas: CER, WER, F1-score</li>
<li>
<p>Comparativa con baseline (solo Tesseract)</p>
</li>
<li>
<p><strong>Análisis de Resultados</strong></p>
</li>
<li>Gráficos de comparación</li>
<li>Análisis cualitativo de errores</li>
<li>
<p>Identificación de casos donde falla el sistema</p>
</li>
<li>
<p><strong>Documento Académico (20-25 páginas)</strong></p>
</li>
<li>Introducción y contexto</li>
<li><strong>Estado del Arte</strong> (5-7 pág)<ul>
<li>Revisión de soluciones IDP comerciales</li>
<li>Papers de OCR (TrOCR, PaddleOCR)</li>
<li>Papers de Inpainting (LaMa, DeepFill)</li>
</ul>
</li>
<li><strong>Metodología</strong> (5-7 pág)<ul>
<li>Arquitectura del sistema</li>
<li>Descripción de algoritmos</li>
<li>Dataset y métricas</li>
</ul>
</li>
<li><strong>Resultados</strong> (4-5 pág)<ul>
<li>Tablas de métricas</li>
<li>Gráficos comparativos</li>
<li>Análisis de experimento de inpainting</li>
</ul>
</li>
<li>
<p><strong>Conclusiones</strong> (2-3 pág)</p>
<ul>
<li>Logros alcanzados</li>
<li>Limitaciones</li>
<li>Trabajo futuro</li>
</ul>
</li>
<li>
<p><strong>Presentación</strong></p>
</li>
<li>10 slides para sustentación</li>
<li>Demo en vivo (Jupyter Notebook)</li>
<li>Video explicativo (3-5 min)</li>
</ol>
<h3>Criterio de Éxito:</h3>
<ul>
<li>✅ Resultados reproducibles</li>
<li>✅ Documento bien estructurado y referenciado</li>
<li>✅ Presentación clara y concisa</li>
</ul>
<hr />
<h1>Plan de Verificación</h1>
<h2>Métricas de Evaluación</h2>
<h3>Accuracy de OCR</h3>
<ul>
<li><strong>CER (Character Error Rate)</strong>: % de caracteres incorrectos</li>
<li><strong>WER (Word Error Rate)</strong>: % de palabras incorrectas</li>
<li><strong>F1-score</strong>: Para entidades específicas (si aplica)</li>
</ul>
<h3>Validación de Inpainting</h3>
<ul>
<li><strong>LPIPS (Learned Perceptual Image Patch Similarity)</strong>: Calidad perceptual</li>
<li><strong>Comparativa Before/After</strong>: Mejora en CER/WER</li>
</ul>
<h3>Calidad de Código</h3>
<ul>
<li><strong>Test Coverage</strong>: &gt;70% (pytest)</li>
<li><strong>Linting</strong>: Pasar flake8 sin warnings críticos</li>
</ul>
<h2>Proceso de Testing</h2>
<h3>1. Tests Unitarios</h3>
<pre><code class="language-python">def test_rotation_correction():
    rotated_img = generate_rotated_image(angle=15)
    corrected = correct_rotation(rotated_img)
    assert get_rotation_angle(corrected) &lt; 2  # tolerance
</code></pre>
<h3>2. Tests de Integración</h3>
<pre><code class="language-python">def test_pipeline_end_to_end():
    img = load_test_image()
    text = pipeline_v2(img)
    assert len(text) &gt; 0
    assert calculate_cer(text, ground_truth) &lt; 0.3
</code></pre>
<h3>3. Benchmarking</h3>
<ul>
<li>Correr pipeline en SROIE test set</li>
<li>Guardar resultados en CSV</li>
<li>Generar reporte automático con métricas</li>
</ul>
<hr />
<h1>Decisiones de Alcance</h1>
<h2>✅ Lo que SÍ haremos</h2>
<ol>
<li><strong>Preprocesamiento robusto</strong> (rotación + binarización)</li>
<li><strong>OCR dual</strong> con fallback inteligente</li>
<li><strong>Detección de sellos</strong> (método simple pero efectivo)</li>
<li><strong>Inpainting con LaMa</strong> (diferenciador clave)</li>
<li><strong>Validación científica</strong> en dataset público</li>
<li><strong>Documentación académica completa</strong></li>
</ol>
<h2>❌ Lo que NO haremos (descartado por tiempo)</h2>
<ol>
<li><strong>Layout Analysis</strong> - Detección de regiones con LayoutLMv3</li>
<li>Razón: Complejidad alta, valor agregado marginal</li>
<li>
<p>Ahorro: ~25 horas</p>
</li>
<li>
<p><strong>Extracción de Tablas</strong> - Camelot/Tabula</p>
</li>
<li>Razón: Requiere fine-tuning extenso</li>
<li>
<p>Ahorro: ~30 horas</p>
</li>
<li>
<p><strong>Extracción de Gráficas</strong> - PlotDigitizer</p>
</li>
<li>Razón: Caso de uso muy específico</li>
<li>
<p>Ahorro: ~30 horas</p>
</li>
<li>
<p><strong>QA Semántico con RAG</strong> </p>
</li>
<li>Razón: Complejidad de implementar LLMs + vector DB</li>
<li>
<p>Ahorro: ~20 horas</p>
</li>
<li>
<p><strong>Fine-tuning de YOLO</strong></p>
</li>
<li>Razón: Detector HSV es suficiente para demostrar concepto</li>
<li>
<p>Ahorro: ~15 horas</p>
</li>
<li>
<p><strong>Dockerización</strong></p>
</li>
<li>Razón: Ejecución local es suficiente para proyecto académico</li>
<li>
<p>Ahorro: ~8 horas</p>
</li>
<li>
<p><strong>Demo en cloud</strong></p>
</li>
<li>Razón: Jupyter Notebook local es suficiente</li>
<li>Ahorro: ~10 horas</li>
</ol>
<p><strong>Total ahorrado: ~138 horas</strong> → Hace el proyecto factible</p>
<hr />
<h1>Limitaciones Reconocidas</h1>
<h2>Técnicas</h2>
<ol>
<li><strong>Detector de sellos simplificado</strong></li>
<li>Basado en color, no en forma/contexto</li>
<li>Puede tener falsos positivos con elementos rojos/azules</li>
<li>
<p>Mejora futura: YOLO fine-tuned</p>
</li>
<li>
<p><strong>Sin manejo de layouts complejos</strong></p>
</li>
<li>No reordena texto según lectura visual</li>
<li>Asume orden secuencial</li>
<li>
<p>Mejora futura: LayoutParser</p>
</li>
<li>
<p><strong>Evaluación en subset de SROIE</strong></p>
</li>
<li>100 muestras, no dataset completo</li>
<li>Suficiente para validación académica</li>
<li>Mejora futura: Benchmark completo</li>
</ol>
<h2>De Alcance</h2>
<ol>
<li><strong>No es un producto de producción</strong></li>
<li>Es un prototipo académico</li>
<li>No tiene consideraciones de escalabilidad</li>
<li>
<p>No tiene manejo de errores exhaustivo</p>
</li>
<li>
<p><strong>Enfoque en documentos con sellos</strong></p>
</li>
<li>No generaliza a todos los tipos de documentos</li>
<li>Optimizado para caso de uso específico</li>
</ol>
<hr />
<h1>Checkpoints y Validación con Asesor</h1>
<h2>CP0 (18 Feb): Setup</h2>
<ul>
<li><strong>Mostrar:</strong> Dataset anotado + infraestructura</li>
<li><strong>Validar:</strong> ¿Es suficiente calidad de dataset?</li>
</ul>
<h2>CP1 (11 Mar): MVP</h2>
<ul>
<li><strong>Mostrar:</strong> Demo de pipeline v1 en vivo</li>
<li><strong>Validar:</strong> ¿OCR &gt;70% accuracy?</li>
<li><strong>Crítico:</strong> Si falla, proyecto no aprueba</li>
</ul>
<h2>CP2 (8 Abr): Inpainting</h2>
<ul>
<li><strong>Mostrar:</strong> Resultados Before/After en 30 muestras</li>
<li><strong>Validar:</strong> ¿Mejora &gt;5% es estadísticamente significativa?</li>
<li><strong>Decisión:</strong> Si NO mejora, documentar por qué y ajustar enfoque</li>
</ul>
<h2>CP3 (29 Abr): Resultados</h2>
<ul>
<li><strong>Mostrar:</strong> Documento académico completo</li>
<li><strong>Validar:</strong> ¿Metodología es clara? ¿Resultados son reproducibles?</li>
</ul>
<h2>Final (30 May): Sustentación</h2>
<ul>
<li><strong>Presentar:</strong> Proyecto completo ante jurado</li>
<li><strong>Defender:</strong> Decisiones técnicas y resultados</li>
</ul>
<hr />
<h1>Recursos Necesarios</h1>
<h2>Computacionales</h2>
<ul>
<li><strong>GPU:</strong> NVIDIA con &gt;=8GB VRAM (para LaMa)</li>
<li>Opción 1: Lab de universidad</li>
<li>Opción 2: Google Colab Pro ($10/mes)</li>
<li>Opción 3: AWS credits (educate)</li>
</ul>
<h2>Humanos</h2>
<ul>
<li><strong>Asesor académico:</strong> Reuniones semanales (30-60 min)</li>
<li><strong>Yo:</strong> 15-18 horas/semana dedicadas</li>
</ul>
<h2>Bibliográficos</h2>
<ul>
<li>Papers de referencia (acceso vía universidad)</li>
<li>Documentación oficial de librerías</li>
</ul>
<hr />
<h1>Conclusión</h1>
<p>Este plan de implementación prioriza <strong>calidad sobre cantidad</strong>, enfocándose en demostrar un concepto innovador (inpainting para mejorar OCR) de forma científicamente rigurosa.</p>
<p>La meta de <strong>7.5/10</strong> es realista y <strong>muy buena</strong> académicamente, reconociendo las limitaciones de tiempo de un estudiante que trabaja.</p>
<p><strong>Próximo paso:</strong> Iniciar CP0 - Setup del proyecto.</p>
<hr />
<p><strong>Manuel Cruz Garrote</strong><br />
Universidad del Rosario<br />
Febrero 2026</p>
    </div>
</body>
</html>