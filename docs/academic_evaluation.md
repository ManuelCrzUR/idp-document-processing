# Proyecto IDP - Sistema de Checkpoints Incrementales
## Universidad del Rosario - IngenierÃ­a de Sistemas

### ğŸ‘¨â€ğŸ« DiseÃ±ado por: Dr. AndrÃ©s Parra Rojas, PhD
**Modalidad:** Proyecto de Grado / Trabajo de InvestigaciÃ³n  
**DuraciÃ³n:** 16-18 semanas (1 semestre acadÃ©mico)  
**CrÃ©ditos:** 6-8 crÃ©ditos acadÃ©micos

---

## ğŸ¯ FILOSOFÃA DEL SISTEMA DE CHECKPOINTS

### **Concepto: "Escalera de Valor Incremental"**

Cada checkpoint representa un **entregable funcional completo** que:
- âœ… Tiene valor acadÃ©mico independiente
- âœ… Es evaluable objetivamente
- âœ… Construye sobre el checkpoint anterior
- âœ… Permite detener el proyecto en cualquier punto sin "fracaso"

**AnalogÃ­a:** Es como construir un edificio piso por piso. Cada piso es habitable, pero mÃ¡s pisos = mÃ¡s valor.

---

## ğŸ“Š ESTRUCTURA DE CALIFICACIÃ“N POR CHECKPOINTS

| Checkpoint | Entregable | Nota MÃ¡xima | % del Total | Acumulado |
|-----------|-----------|-------------|-------------|-----------|
| **CP0: Setup** | Infraestructura + Dataset | 1.0 | 10% | 1.0 |
| **CP1: MVP Core** | Preprocesamiento + OCR | 2.5 | 25% | 3.5 |
| **CP2: Diferenciador** | DetecciÃ³n + Inpainting Sellos | 2.5 | 25% | 6.0 |
| **CP3: ValidaciÃ³n** | Experimentos + Resultados | 1.5 | 15% | 7.5 |
| **CP4: Features Avanzadas** | Layout + Tablas | 1.5 | 15% | 9.0 |
| **CP5: Excelencia** | Paper + Demo + CÃ³digo Prod | 1.0 | 10% | **10.0** âœ¨ |

### **InterpretaciÃ³n de Notas:**

- **3.5 (CP0+CP1):** Aprobado - Sistema funcional bÃ¡sico
- **6.0 (hasta CP2):** Bueno - Con diferenciador innovador
- **7.5 (hasta CP3):** Muy Bueno - ValidaciÃ³n rigurosa
- **9.0 (hasta CP4):** Sobresaliente - Sistema completo
- **10.0 (CP5):** Excelencia - ContribuciÃ³n cientÃ­fica

---

## ğŸ—“ï¸ CRONOGRAMA DE 16 SEMANAS

### **CHECKPOINT 0: Fundamentos (Semanas 1-3)** â†’ Nota: 1.0/10

#### **Objetivo:** Preparar el terreno tÃ©cnico y teÃ³rico

#### **Semana 1: InvestigaciÃ³n Inicial**
**Actividades:**
- [ ] Lectura de 10 papers core (OCR, Inpainting, IDP)
- [ ] AnÃ¡lisis del problema (documentos con sellos)
- [ ] DefiniciÃ³n de objetivos SMART del proyecto
- [ ] Setup de ambiente (Python, PyTorch, GPU)

**Entregables:**
- ğŸ“„ Documento "Planteamiento del Problema" (3-4 pÃ¡ginas)
- ğŸ“š Tabla comparativa de 3 soluciones existentes
- âœ… Repositorio GitHub inicializado

**Tiempo:** 25 horas

---

#### **Semana 2: Dataset - Parte 1**
**Actividades:**
- [ ] Descargar SROIE dataset
- [ ] AnÃ¡lisis exploratorio de datos (EDA)
- [ ] Definir estrategia de anotaciÃ³n de sellos
- [ ] Scrapar 50 imÃ¡genes con sellos (web scraping)

**Entregables:**
- ğŸ’¾ SROIE descargado y organizado
- ğŸ“Š Notebook de EDA (estadÃ­sticas del dataset)
- ğŸ–¼ï¸ 50 imÃ¡genes con sellos recolectadas

**Tiempo:** 20 horas

---

#### **Semana 3: Dataset - Parte 2**
**Actividades:**
- [ ] Anotar 100 sellos con LabelImg/CVAT
- [ ] Data augmentation (rotaciÃ³n, ruido, blur)
- [ ] Split: Train 70% / Val 15% / Test 15%
- [ ] Documentar proceso de anotaciÃ³n

**Entregables:**
- ğŸ’¾ **Dataset de Sellos Anotado** (100+ imÃ¡genes)
- ğŸ“„ Documento de "MetodologÃ­a de Dataset" (2-3 pÃ¡ginas)
- âœ… Scripts de augmentation

**Tiempo:** 25 horas

---

#### **ğŸ“‹ EvaluaciÃ³n CP0 (3.0 puntos totales):**

| Criterio | Puntos |
|----------|--------|
| Repositorio configurado correctamente | 0.2 |
| Dataset SROIE descargado y analizado | 0.2 |
| Dataset de sellos anotado (mÃ­n 80 samples) | 0.3 |
| DocumentaciÃ³n de metodologÃ­a | 0.2 |
| EDA con visualizaciones | 0.1 |
| **TOTAL CP0** | **1.0** |

**Nota acumulada hasta aquÃ­: 1.0/10**

---

### **CHECKPOINT 1: MVP Core - Sistema Base (Semanas 4-7)** â†’ Nota: +2.5/10

#### **Objetivo:** Pipeline funcional de preprocesamiento + OCR

#### **Semana 4: Preprocesamiento - Parte 1**
**Actividades:**
- [ ] Implementar correcciÃ³n de rotaciÃ³n (Hough transform)
- [ ] Implementar correcciÃ³n de perspectiva (4-point transform)
- [ ] Tests unitarios con pytest
- [ ] Notebook de demostraciÃ³n visual

**Entregables:**
- ğŸ’» `preprocessing/rotation.py`
- ğŸ’» `preprocessing/perspective.py`
- ğŸ“Š Notebook "Demo_Preprocessing_1.ipynb"
- âœ… Tests unitarios (>70% coverage)

**Tiempo:** 25 horas

---

#### **Semana 5: Preprocesamiento - Parte 2**
**Actividades:**
- [ ] Implementar denoising (3 mÃ©todos)
- [ ] Implementar binarizaciÃ³n adaptativa
- [ ] Benchmarking de mÃ©todos (PSNR, SSIM)
- [ ] MÃ³dulo unificado de preprocesamiento

**Entregables:**
- ğŸ’» `preprocessing/denoising.py`
- ğŸ’» `preprocessing/binarization.py`
- ğŸ“Š Tabla comparativa de mÃ©todos
- âœ… API unificada `preprocess_image()`

**Tiempo:** 25 horas

---

#### **Semana 6: OCR Engine**
**Actividades:**
- [ ] Wrapper para Tesseract
- [ ] Wrapper para PaddleOCR
- [ ] Estrategia de fallback automÃ¡tico
- [ ] MediciÃ³n de accuracy en SROIE (subset)

**Entregables:**
- ğŸ’» `ocr/ocr_engine.py`
- ğŸ“Š Benchmark: Tesseract vs PaddleOCR
- ğŸ“ˆ Accuracy en 100 muestras de SROIE
- âœ… API `extract_text(image)`

**Tiempo:** 30 horas

---

#### **Semana 7: Pipeline v1 + IntegraciÃ³n**
**Actividades:**
- [ ] Integrar preprocesamiento + OCR
- [ ] Script end-to-end `pipeline_v1.py`
- [ ] Dockerizar aplicaciÃ³n
- [ ] DocumentaciÃ³n de API

**Entregables:**
- ğŸ’» `pipeline_v1.py` (completo)
- ğŸ³ `Dockerfile` funcional
- ğŸ“„ README con instrucciones de uso
- ğŸ¥ Video demo (2 min)

**Tiempo:** 25 horas

---

#### **ğŸ“‹ EvaluaciÃ³n CP1 (2.5 puntos):**

| Criterio | Puntos |
|----------|--------|
| Preprocesamiento funcional (3+ mÃ©todos) | 0.6 |
| OCR con 2+ engines | 0.5 |
| Pipeline integrado end-to-end | 0.6 |
| CÃ³digo limpio + tests (>70% coverage) | 0.3 |
| Dockerizado y documentado | 0.3 |
| Accuracy OCR >70% en subset SROIE | 0.2 |
| **TOTAL CP1** | **2.5** |

**Nota acumulada hasta aquÃ­: 3.5/10** âœ… **APROBADO**

**ğŸ“ DecisiÃ³n acadÃ©mica:** Si el estudiante detiene aquÃ­, tiene un proyecto aprobado con sistema funcional bÃ¡sico.

---

### **CHECKPOINT 2: Diferenciador Innovador (Semanas 8-11)** â†’ Nota: +2.5/10

#### **Objetivo:** Implementar la feature Ãºnica (Inpainting de Sellos)

#### **Semana 8: DetecciÃ³n de Sellos - Enfoque ClÃ¡sico**
**Actividades:**
- [ ] Implementar detecciÃ³n por color (HSV thresholding)
- [ ] Implementar detecciÃ³n por forma (Hough circles)
- [ ] Benchmarking en dataset de sellos
- [ ] AnÃ¡lisis de falsos positivos/negativos

**Entregables:**
- ğŸ’» `stamps/detector_classic.py`
- ğŸ“Š MÃ©tricas: Precision, Recall, F1-score
- ğŸ“ˆ Confusion matrix
- âœ… VisualizaciÃ³n de detecciones

**Tiempo:** 25 horas

---

#### **Semana 9: DetecciÃ³n de Sellos - Deep Learning**
**Actividades:**
- [ ] Fine-tune YOLOv8 en dataset de sellos
- [ ] Training (50 epochs mÃ­nimo)
- [ ] EvaluaciÃ³n en test set
- [ ] Comparar YOLO vs mÃ©todos clÃ¡sicos

**Entregables:**
- ğŸ’» `stamps/detector_yolo.py`
- ğŸ¤– Modelo entrenado `.pt` file
- ğŸ“Š Curvas de entrenamiento (loss, mAP)
- ğŸ“ˆ Tabla comparativa: Classic vs YOLO

**Tiempo:** 30 horas

---

#### **Semana 10: Inpainting con LaMa**
**Actividades:**
- [ ] Integrar LaMa (clonar repo, download weights)
- [ ] Implementar wrapper en Python
- [ ] Testear en 30 imÃ¡genes con sellos
- [ ] Medir calidad de inpainting (LPIPS, FID)

**Entregables:**
- ğŸ’» `stamps/inpainting.py`
- ğŸ“Š MÃ©tricas de calidad (PSNR, SSIM, LPIPS)
- ğŸ“· GalerÃ­a Before/After (20 ejemplos)
- âœ… Comparativa con cv2.inpaint (baseline)

**Tiempo:** 30 horas

---

#### **Semana 11: Pipeline v2 - Con Inpainting**
**Actividades:**
- [ ] Integrar detecciÃ³n + inpainting en pipeline
- [ ] **Experimento crÃ­tico:** OCR Before/After inpainting
- [ ] AnÃ¡lisis estadÃ­stico (paired t-test)
- [ ] OptimizaciÃ³n de hiperparÃ¡metros

**Entregables:**
- ğŸ’» `pipeline_v2.py` (con sellos)
- ğŸ“Š **Tabla de resultados:** CER Before vs After
- ğŸ“ˆ AnÃ¡lisis estadÃ­stico (p-value <0.05)
- ğŸ¥ Video demo comparativo

**Tiempo:** 30 horas

---

#### **ğŸ“‹ EvaluaciÃ³n CP2 (2.5 puntos):**

| Criterio | Puntos |
|----------|--------|
| Detector de sellos funcional (mAP >0.6) | 0.6 |
| Inpainting integrado correctamente | 0.5 |
| **Mejora cuantificable en OCR (>5%)** | 0.8 |
| AnÃ¡lisis estadÃ­stico riguroso | 0.3 |
| Comparativa de enfoques (classic vs DL) | 0.2 |
| DocumentaciÃ³n de experimento crÃ­tico | 0.1 |
| **TOTAL CP2** | **2.5** |

**Nota acumulada hasta aquÃ­: 6.0/10** âœ… **BUENO**

**ğŸ“ DecisiÃ³n acadÃ©mica:** Si detiene aquÃ­, tiene un proyecto bueno con aporte innovador validado.

---

### **CHECKPOINT 3: ValidaciÃ³n Rigurosa (Semanas 12-13)** â†’ Nota: +1.5/10

#### **Objetivo:** Demostrar resultados cientÃ­ficamente vÃ¡lidos

#### **Semana 12: EvaluaciÃ³n en SROIE Completo**
**Actividades:**
- [ ] Correr pipeline en SROIE test set completo
- [ ] Calcular mÃ©tricas oficiales (F1 por entidad)
- [ ] Comparar con baselines (solo Tesseract, solo PaddleOCR)
- [ ] AnÃ¡lisis de errores (Â¿quÃ© falla y por quÃ©?)

**Entregables:**
- ğŸ“Š **Tabla de Resultados vs Baselines**
- ğŸ“ˆ GrÃ¡ficos de comparaciÃ³n
- ğŸ“„ SecciÃ³n "Resultados" del documento (5-7 pÃ¡ginas)
- ğŸ’¾ Predicciones guardadas (para reproducibilidad)

**Tiempo:** 30 horas

---

#### **Semana 13: Ablation Study + DocumentaciÃ³n**
**Actividades:**
- [ ] Ablation study: Â¿QuÃ© componente aporta mÃ¡s?
  - Pipeline sin preprocesamiento
  - Pipeline sin inpainting
  - Pipeline completo
- [ ] Redactar secciÃ³n de MetodologÃ­a
- [ ] Redactar Estado del Arte

**Entregables:**
- ğŸ“Š Tabla de Ablation Study
- ğŸ“„ MetodologÃ­a (8-10 pÃ¡ginas)
- ğŸ“„ Estado del Arte (10-12 pÃ¡ginas)
- ğŸ“š Referencias bibliogrÃ¡ficas (mÃ­n 15 papers)

**Tiempo:** 35 horas

---

#### **ğŸ“‹ EvaluaciÃ³n CP3 (1.5 puntos):**

| Criterio | Puntos |
|----------|--------|
| EvaluaciÃ³n completa en SROIE | 0.4 |
| Comparativa con 2+ baselines | 0.3 |
| Ablation study riguroso | 0.4 |
| DocumentaciÃ³n metodolÃ³gica | 0.3 |
| Estado del arte bien fundamentado | 0.1 |
| **TOTAL CP3** | **1.5** |

**Nota acumulada hasta aquÃ­: 7.5/10** âœ… **MUY BUENO**

**ğŸ“ DecisiÃ³n acadÃ©mica:** Proyecto muy bueno, cumple con estÃ¡ndares de tesis de grado.

---

### **CHECKPOINT 4: Features Avanzadas (Semanas 14-16)** â†’ Nota: +1.5/10

#### **Objetivo:** Sistema completo de IDP

#### **Semana 14: Layout Analysis**
**Actividades:**
- [ ] Integrar LayoutParser o LayoutLMv3
- [ ] Detectar regiones: Texto, Tablas, ImÃ¡genes
- [ ] Benchmarking en PubLayNet (subset)
- [ ] Integrar en pipeline principal

**Entregables:**
- ğŸ’» `layout/layout_analyzer.py`
- ğŸ“Š IoU por tipo de regiÃ³n
- ğŸ¨ Visualizaciones de layout detectado
- âœ… API `analyze_layout(image)`

**Tiempo:** 30 horas

---

#### **Semana 15: ExtracciÃ³n de Tablas**
**Actividades:**
- [ ] Implementar Camelot (Lattice + Stream)
- [ ] Implementar PDFPlumber como fallback
- [ ] Estrategia hÃ­brida automÃ¡tica
- [ ] EvaluaciÃ³n en dataset de tablas

**Entregables:**
- ğŸ’» `tables/table_extractor.py`
- ğŸ“Š Tasa de extracciÃ³n correcta (>75%)
- ğŸ“‹ Ejemplos de tablas extraÃ­das (CSV/JSON)
- âœ… API `extract_tables(document)`

**Tiempo:** 30 horas

---

#### **Semana 16: Pipeline v3 Final + OptimizaciÃ³n**
**Actividades:**
- [ ] Integrar layout + tables en pipeline
- [ ] OptimizaciÃ³n de latencia (<15s por doc)
- [ ] Refactoring de cÃ³digo
- [ ] DocumentaciÃ³n de API completa

**Entregables:**
- ğŸ’» `pipeline_v3.py` (sistema completo)
- ğŸ“Š Profiling de performance
- ğŸ“„ Swagger/OpenAPI documentation
- ğŸ³ Docker optimizado

**Tiempo:** 35 horas

---

#### **ğŸ“‹ EvaluaciÃ³n CP4 (1.5 puntos):**

| Criterio | Puntos |
|----------|--------|
| Layout analysis funcional | 0.4 |
| ExtracciÃ³n de tablas (>75% success rate) | 0.5 |
| Pipeline completo integrado | 0.3 |
| OptimizaciÃ³n de latencia (<15s/doc) | 0.2 |
| DocumentaciÃ³n de API | 0.1 |
| **TOTAL CP4** | **1.5** |

**Nota acumulada hasta aquÃ­: 9.0/10** â­ **SOBRESALIENTE**

**ğŸ“ DecisiÃ³n acadÃ©mica:** Proyecto sobresaliente, supera expectativas de pregrado.

---

### **CHECKPOINT 5: Excelencia AcadÃ©mica (Semanas 17-18)** â†’ Nota: +1.0/10

#### **Objetivo:** ContribuciÃ³n cientÃ­fica y profesionalizaciÃ³n

#### **Semana 17: Paper AcadÃ©mico**
**Actividades:**
- [ ] Redactar paper (formato IEEE, 6-8 pÃ¡ginas)
  - Abstract
  - Introduction
  - Related Work
  - Methodology
  - Experiments
  - Results
  - Conclusion
- [ ] Generar figuras de calidad publicable
- [ ] RevisiÃ³n con asesor

**Entregables:**
- ğŸ“„ **Paper en formato IEEE** (LaTeX)
- ğŸ“Š Figuras en alta resoluciÃ³n
- ğŸ“š Referencias en BibTeX

**Tiempo:** 35 horas

---

#### **Semana 18: Demo Profesional + CÃ³digo ProducciÃ³n**
**Actividades:**
- [ ] Crear demo interactiva (Streamlit/Gradio)
- [ ] Desplegar en cloud (Hugging Face Spaces / Railway)
- [ ] CÃ³digo production-ready:
  - CI/CD con GitHub Actions
  - Tests automatizados (>80% coverage)
  - Logging estructurado
  - Error handling robusto
- [ ] DocumentaciÃ³n completa (README, CONTRIBUTING, API docs)

**Entregables:**
- ğŸŒ **Demo en vivo** (URL pÃºblica)
- ğŸ’» Repositorio production-ready
- ğŸ“„ DocumentaciÃ³n exhaustiva
- ğŸ¥ Video explicativo (5-7 min)

**Tiempo:** 35 horas

---

#### **ğŸ“‹ EvaluaciÃ³n CP5 (1.0 punto):**

| Criterio | Puntos |
|----------|--------|
| Paper en formato IEEE (completo) | 0.4 |
| Demo interactiva desplegada | 0.3 |
| CÃ³digo production-ready (CI/CD, tests) | 0.2 |
| Video explicativo profesional | 0.1 |
| **TOTAL CP5** | **1.0** |

**Nota acumulada hasta aquÃ­: 10.0/10** ğŸ† **EXCELENCIA**

**ğŸ“ DecisiÃ³n acadÃ©mica:** Proyecto de excelencia, candidato a mejor proyecto del aÃ±o.

---

## ğŸ“Š RESUMEN DE TIEMPOS POR CHECKPOINT

| Checkpoint | Semanas | Horas Totales | Horas/Semana | Nota Acum. |
|-----------|---------|---------------|--------------|------------|
| CP0 | 3 | 70 h | 23 | 1.0 |
| CP1 | 4 | 105 h | 26 | 3.5 âœ… |
| CP2 | 4 | 115 h | 29 | 6.0 |
| CP3 | 2 | 65 h | 33 | 7.5 |
| CP4 | 3 | 95 h | 32 | 9.0 â­ |
| CP5 | 2 | 70 h | 35 | 10.0 ğŸ† |
| **TOTAL** | **18** | **520 h** | **~29 h/sem** | |

**Nota:** El promedio de 29 horas/semana es intensivo pero manejable para un proyecto de grado full-time.

---

## ğŸ¯ ESTRATEGIAS DE MITIGACIÃ“N DE RIESGOS

### **Si el estudiante va retrasado:**

#### **En Semana 8 (inicio CP2):**
- âŒ Si CP0+CP1 no estÃ¡n completos â†’ **DETENER**
- âœ… Remedial: Completar CP1 antes de continuar
- â±ï¸ ExtensiÃ³n: +2 semanas mÃ¡ximo

#### **En Semana 12 (inicio CP3):**
- âŒ Si inpainting NO mejora OCR >5% â†’ **PIVOTAR**
- âœ… Plan B: Descope inpainting, enfocarse en preprocesamiento robusto
- ğŸ“Š Mantener nota de CP2 si detector de sellos funciona

#### **En Semana 14 (inicio CP4):**
- âš ï¸ Si tiempo es limitado â†’ **PRIORIZAR**
- âœ… OpciÃ³n 1: Solo layout (sin tablas) â†’ 9.0 es alcanzable
- âœ… OpciÃ³n 2: Solo tablas (sin layout) â†’ 9.0 es alcanzable

---

## ğŸ”„ FLEXIBILIDAD DEL SISTEMA

### **Ventajas del Sistema de Checkpoints:**

1. âœ… **EvaluaciÃ³n Justa:**
   - Estudiante que llega a CP3 tiene 7.5 (muy bueno)
   - No es "todo o nada"

2. âœ… **MotivaciÃ³n Incremental:**
   - Cada checkpoint es un "win"
   - GamificaciÃ³n del aprendizaje

3. âœ… **Adaptabilidad:**
   - Profesor puede ajustar pesos segÃºn contexto
   - Estudiante puede negociar prioridades

4. âœ… **Transparencia:**
   - Criterios claros desde el inicio
   - No hay sorpresas en la evaluaciÃ³n

---

## ğŸ“‹ RÃšBRICA DETALLADA POR CHECKPOINT

### **CP0: Fundamentos (1.0 punto)**

| Criterio | Excelente (1.0) | Bueno (0.7) | Suficiente (0.5) | Insuficiente (0.0) |
|----------|----------------|-------------|------------------|--------------------|
| **Dataset Anotado** | 100+ sellos, alta calidad | 80+ sellos, calidad media | 50+ sellos | <50 sellos |
| **DocumentaciÃ³n** | Completa, profesional | Suficiente | BÃ¡sica | Falta |
| **Infraestructura** | GPU + Docker + Git | GPU + Git | Solo local | No funciona |

---

### **CP1: MVP Core (2.5 puntos)**

| Criterio | Excelente (2.5) | Bueno (2.0) | Suficiente (1.5) | Insuficiente (<1.5) |
|----------|----------------|-------------|------------------|---------------------|
| **Preprocesamiento** | 3+ mÃ©todos, bien implementados | 2 mÃ©todos | 1 mÃ©todo funcional | No funciona |
| **OCR** | 2 engines + fallback | 1 engine robusto | 1 engine bÃ¡sico | No extrae texto |
| **Pipeline** | Dockerizado, documentado | Funcional | Funciona localmente | Errores frecuentes |
| **Accuracy** | >80% SROIE | 70-80% | 60-70% | <60% |

---

### **CP2: Diferenciador (2.5 puntos)**

| Criterio | Excelente (2.5) | Bueno (2.0) | Suficiente (1.5) | Insuficiente (<1.5) |
|----------|----------------|-------------|------------------|---------------------|
| **DetecciÃ³n Sellos** | YOLO mAP >0.8 | mAP 0.6-0.8 | Detector clÃ¡sico funcional | No detecta |
| **Inpainting** | LaMa integrado | cv2.inpaint funcional | Inpainting bÃ¡sico | No implementado |
| **Mejora OCR** | >15% mejora | 10-15% | 5-10% | <5% |
| **ValidaciÃ³n** | AnÃ¡lisis estadÃ­stico riguroso | Comparativa bÃ¡sica | Solo ejemplos visuales | Sin validaciÃ³n |

---

### **CP3: ValidaciÃ³n (1.5 puntos)**

| Criterio | Excelente (1.5) | Bueno (1.2) | Suficiente (0.9) | Insuficiente (<0.9) |
|----------|----------------|-------------|------------------|---------------------|
| **Benchmark SROIE** | Test completo, mÃºltiples mÃ©tricas | Test parcial | Solo accuracy | Sin benchmark |
| **Ablation Study** | 3+ variantes comparadas | 2 variantes | AnÃ¡lisis superficial | No realizado |
| **DocumentaciÃ³n** | MetodologÃ­a + Estado del Arte | Solo metodologÃ­a | DocumentaciÃ³n bÃ¡sica | Incompleta |

---

### **CP4: Features Avanzadas (1.5 puntos)**

| Criterio | Excelente (1.5) | Bueno (1.2) | Suficiente (0.9) | Insuficiente (<0.9) |
|----------|----------------|-------------|------------------|---------------------|
| **Layout Analysis** | LayoutLMv3, IoU >0.75 | LayoutParser bÃ¡sico | DetecciÃ³n manual | No implementado |
| **Tablas** | HÃ­brido, >85% accuracy | Camelot solo | ExtracciÃ³n bÃ¡sica | No funciona |
| **IntegraciÃ³n** | Pipeline unificado optimizado | Pipeline funcional | MÃ³dulos separados | Sin integraciÃ³n |

---

### **CP5: Excelencia (1.0 punto)**

| Criterio | Excelente (1.0) | Bueno (0.7) | Suficiente (0.5) | Insuficiente (0.0) |
|----------|----------------|-------------|------------------|---------------------|
| **Paper IEEE** | Completo, listo para submit | Draft sÃ³lido | Estructura bÃ¡sica | No escrito |
| **Demo** | Desplegada en cloud, UX profesional | Demo local funcional | Jupyter notebook | No hay demo |
| **CÃ³digo Prod** | CI/CD, tests >80%, docs | Tests bÃ¡sicos | CÃ³digo limpio | Sin tests |

---

## ğŸ“ RECOMENDACIONES PEDAGÃ“GICAS

### **Para el Estudiante:**

1. âœ… **No saltar checkpoints**
   - Cada CP es prerequisito del siguiente
   - Validar con profesor antes de avanzar

2. âœ… **Priorizar calidad sobre cantidad**
   - Mejor un CP3 excelente que CP4 mediocre
   - 7.5 muy bien hecho > 9.0 incompleto

3. âœ… **Checkpoints semanales con asesor**
   - ReuniÃ³n de 30 min cada viernes
   - Demo de avance + planning prÃ³xima semana

4. âœ… **Documentar mientras desarrollas**
   - No dejar escritura para el final
   - Cada experimento â†’ secciÃ³n de Resultados

---

### **Para el Profesor:**

1. âœ… **EvaluaciÃ³n continua:**
   - Revisar entregables en <48 horas
   - Feedback especÃ­fico y accionable

2. âœ… **Flexibilidad controlada:**
   - Permitir negociaciÃ³n de CP4 (layout vs tablas)
   - NO permitir saltar CP2 (es el core innovador)

3. âœ… **Puntos de decisiÃ³n claros:**
   - Semana 11: Â¿Continuar con CP3 o reforzar CP2?
   - Semana 14: Â¿Ir por CP5 o perfeccionar CP4?

---

## ğŸ“ˆ CASOS DE USO DEL SISTEMA

### **Caso 1: Estudiante Ambicioso (Nota Objetivo: 10.0)**
- Semanas 1-11: CP0â†’CP2 sin problemas
- Semanas 12-13: CP3 con ablation study extenso
- Semanas 14-16: CP4 completo (layout + tablas)
- Semanas 17-18: CP5 (paper + demo cloud)
- **Resultado:** 10.0 + MenciÃ³n de Honor

---

### **Caso 2: Estudiante Realista (Nota Objetivo: 8.0-9.0)**
- Semanas 1-11: CP0â†’CP2 (dedicar mÃ¡s tiempo a inpainting)
- Semanas 12-13: CP3 sÃ³lido
- Semanas 14-16: CP4 (solo tablas, descope layout)
- **Resultado:** 8.5-9.0 Sobresaliente

---

### **Caso 3: Estudiante con Contratiempos (Nota Objetivo: 7.0-7.5)**
- Semanas 1-7: CP0+CP1 (retrasado 1 semana)
- Semanas 8-13: CP2 (inpainting mejora solo 8%, acepta)
- Semanas 14-16: CP3 (validaciÃ³n bÃ¡sica)
- **Resultado:** 7.0-7.5 Muy Bueno (aprobado con mÃ©rito)

---

## ğŸ† CONCLUSIONES

### **Por quÃ© este sistema es mejor:**

1. âœ… **Reduce ansiedad:** Estudiante sabe exactamente dÃ³nde estÃ¡
2. âœ… **Fomenta excelencia:** Cada CP es un reto alcanzable
3. âœ… **EvaluaciÃ³n justa:** No se penaliza por no llegar al final
4. âœ… **Escalable:** Profesor puede adaptar pesos segÃºn curso
5. âœ… **Calidad garantizada:** CP1 asegura proyecto funcional mÃ­nimo

### **Mejora sobre plan original:**

| Aspecto | Plan Original (8-10 meses) | Plan Checkpoints (16-18 sem) |
|---------|---------------------------|------------------------------|
| **DuraciÃ³n** | 32-40 semanas | 16-18 semanas âœ… |
| **EvaluaciÃ³n** | Final (todo o nada) | Incremental âœ… |
| **Calidad** | Alta | **Igual o mayor** âœ… |
| **Flexibilidad** | Baja | Alta âœ… |
| **MotivaciÃ³n** | Picos y valles | Constante âœ… |

---

**Firma:**

**Dr. AndrÃ©s Parra Rojas, PhD**  
Profesor Titular  
Universidad del Rosario  

**Fecha:** Febrero 2026
